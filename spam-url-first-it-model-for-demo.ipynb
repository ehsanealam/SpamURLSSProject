{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8138,"sourceType":"datasetVersion","datasetId":5423},{"sourceId":461384,"sourceType":"datasetVersion","datasetId":211817},{"sourceId":1057542,"sourceType":"datasetVersion","datasetId":585876},{"sourceId":2191460,"sourceType":"datasetVersion","datasetId":1315718},{"sourceId":2456026,"sourceType":"datasetVersion","datasetId":1486586}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n\ndata = pd.read_csv('/kaggle/input/urldataset/data.csv')\n\n\nprint(\"First few rows of the dataset:\")\nprint(data.head())\n\nprint(\"\\nDimensions of the dataset:\")\nprint(data.shape)\n\n\nprint(\"\\nMissing values in the dataset:\")\nprint(data.isnull().sum())\n\n\nprint(\"\\nDistribution of labels:\")\nprint(data['label'].value_counts())\n\n\nprint(\"\\nStatistics of the dataset:\")\nprint(data.describe())\n\nprint(\"\\nUnique values in the 'label' column:\")\nprint(data['label'].unique())\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-08T01:11:48.677750Z","iopub.execute_input":"2024-03-08T01:11:48.678160Z","iopub.status.idle":"2024-03-08T01:11:50.197870Z","shell.execute_reply.started":"2024-03-08T01:11:48.678130Z","shell.execute_reply":"2024-03-08T01:11:50.196951Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"First few rows of the dataset:\n                      url label\n0  diaryofagameaddict.com   bad\n1        espdesign.com.au   bad\n2      iamagameaddict.com   bad\n3           kalantzis.net   bad\n4   slightlyoffcenter.net   bad\n\nDimensions of the dataset:\n(420464, 2)\n\nMissing values in the dataset:\nurl      0\nlabel    0\ndtype: int64\n\nDistribution of labels:\nlabel\ngood    344821\nbad      75643\nName: count, dtype: int64\n\nStatistics of the dataset:\n                                                  url   label\ncount                                          420464  420464\nunique                                         411247       2\ntop     d11m2p9mpffp32.cloudfront.net/main/web_zt.exe    good\nfreq                                               27  344821\n\nUnique values in the 'label' column:\n['bad' 'good']\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\ndata = pd.read_csv('/kaggle/input/urldataset/data.csv')\n\n\ndata = data.sample(frac=0.5, random_state=42)\n\n\nX = data['url']\ny = data['label']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodels = {\n    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n    \"Multinomial Naive Bayes\": MultinomialNB(),\n}\n\n#  parameter grids for hyperparameter tuning\nparam_grids = {\n    \"Logistic Regression\": {'logisticregression__C': [0.1, 1.0, 10.0]},\n    \"Multinomial Naive Bayes\": {},\n}\n\n\nresults = []\n\nfor model_name, model in models.items():\n    pipeline = make_pipeline(CountVectorizer(ngram_range=(1, 2)), model)  # Using unigrams and bigrams\n    param_grid = param_grids[model_name]\n    grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n    grid_search.fit(X_train, y_train)\n    best_model = grid_search.best_estimator_\n    y_pred = best_model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='weighted')\n    recall = recall_score(y_test, y_pred, average='weighted')\n    f1 = f1_score(y_test, y_pred, average='weighted')\n    results.append({'Model': model_name, 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1})\n\n\nresults_df = pd.DataFrame(results)\n\nprint(results_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-09T20:36:34.191867Z","iopub.execute_input":"2024-03-09T20:36:34.192266Z","iopub.status.idle":"2024-03-09T20:39:52.661829Z","shell.execute_reply.started":"2024-03-09T20:36:34.192229Z","shell.execute_reply":"2024-03-09T20:39:52.660691Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"                     Model  Accuracy  Precision    Recall  F1 Score\n0      Logistic Regression  0.972055   0.972098  0.972055  0.971398\n1  Multinomial Naive Bayes  0.974196   0.974286  0.974196  0.973615\n","output_type":"stream"}]},{"cell_type":"code","source":"import joblib\n\nfor model_name, model in models.items():\n    pipeline = make_pipeline(CountVectorizer(), model)\n    param_grid = param_grids[model_name]\n    grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n    grid_search.fit(X_train, y_train)\n    best_model = grid_search.best_estimator_\n    joblib.dump(best_model, f'{model_name}_model.pkl')\n\nprint(\"Models saved successfully!\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-09T20:40:36.121995Z","iopub.execute_input":"2024-03-09T20:40:36.122812Z","iopub.status.idle":"2024-03-09T20:42:13.394821Z","shell.execute_reply.started":"2024-03-09T20:40:36.122780Z","shell.execute_reply":"2024-03-09T20:42:13.393717Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Models saved successfully!\n","output_type":"stream"}]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}